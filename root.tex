\documentclass[10pt, oneside]{article} 
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry}
\usepackage{hyperref}
\usepackage{ourmacros}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\usepackage{bbm}

\title{Advanced Stochastic Processes Seminar Notes}
\author{AC, DG, JW, TC}

\begin{document}

\maketitle
\tableofcontents

\vspace{.25in}

\section{Motivations for Measure Theoretic Perspective}
Consider the following probability calculation: Let $W\sim U(0,1)$ be a uniformly distributed, 
continuous random variable in the range 0 to 1. Compute $\Pr[W=w\in \Q]$, that is, the 
probability that $w$ is rational.
The probability density function for a standard uniform distribution is given by $\phi(w)=1,0\le w\le1$ and zero otheriwise. 
This can be expressed with indicator function notation as $\phi(w)=\mathbbm{1}_{(0,1)}(w)$.
Given the density function, we may query the probability of the occurence of specific events.
For example, suppose we want to know the probability that $W$ is between 1/3 and 1/2.
This is simply given by the area under the density curve between these two points, and so
$$\Pr[1/3<W<1/2]=\int_{1/3}^{1/2}\mathbbm{1}_{(0,1)}(w)dw=\int_{0}^{1}\mathbbm{1}_{(1/3,1/2)}(w)dw=\int_{0}^{1/3}0dw+\int_{1/3}^{1/2}1dw+\int_{1/2}^{1}0dw=w\Big|_{1/3}^{1/2}=1/6$$

For our desired calculation, we simply need to compute the total area under the density 
curve given by rational values of $w$:
$$\Pr[W=w\in\Q]=\int_{\Q}\mathbbm{1}_{(0,1)}(w)dw=\int_{0}^{1}\mathbbm{1}_{\Q}(w)dw$$
Notice however that we cannot separate this integral into a finite sum of integrals to 
remove the indicator function, as the rationals are dense in the reals, and hence we must 
compute the integral directly.
This leads to a problem, however, which requires machinery from real analysis.
Recall that the computation of a Riemann sum of a function $\phi$ over an interval $[a,b]$ is obtained from partitioning the region $[a,b]$ into slices.
We approximate the area under $\phi$ between $a$ and $b$ by forming these slices into rectangles, whose areas are then summed.
More precisely, we have the following definitions:

\begin{defn}[Partition]
\label{defn:partition}
Let $a,b\in \R$ and suppose $a<b$. A partition of $[a,b]$ is a collection of intervals $P~=~\{[x_0,x_1],[x_1,x_2],\ldots,[x_{n-1},x_n]\}=\{[x_{k-1},x_{k}]\}_{k=1}^n$ where $a=x_0<x_1<x_2<\ldots<x_{n-1}<x_n=b$.
\end{defn}

\begin{defn}[Sampled Partition]
\label{defn:samplepartition}
Let $P=\{[x_{k-1},x_{k}]\}_{k=1}^n$ be a partition over $[a,b]$. If $t_k \in I_k=[x_{k-1},x_k]$ then we say $t_k$ is a sample of $I_k$, and the set of ordered pairs $\dot{P}=\{([x_{k-1},x_{k}],t_k)\}_{k=1}^n$ is a sampled partition of $[a,b]$.
\end{defn}

Without loss of generality, suppose $\phi$ is strictly positive over its whole domain.
One can compute the summation of parts of a sampled partition, where each part $[x_{k-1},x_k]$ is bounded from below by the horizontal axis and from above by a horizontal line at a point $\phi(t_k)$, hence yielding a sum of areas of rectangles.
Given a function $\phi$ and a sampled partition $\dot{P}$ over an interval $[a,b]$, the Riemann sum $S$ is given by 
$$S(\phi,\dot{P})=\sum_{k=1}^n\phi(t_k)(x_k-x_{k-1})$$
This brings us to the following critical definition:

\begin{defn}[Riemann Integrability]
\label{defn:riemann}
A function $\phi:[a,b]\to \R$ is Riemann integrable if there exists $L\in \R$ such that for all $\epsilon>0$ there exists a $\delta >0$ such that for any sampled partition $\dot{P}$ that satisfies $||\dot{P}||~:=~\max_{k\in\{1,\ldots,n\}}\{x_{k}-~x_{k-1}\}<~\delta$, it holds that $|S(\phi,\dot{P})-L|<\epsilon$.
\end{defn}

In other words, for any choice of sampled partition $\dot{P}$, $S(\phi,\dot{P})$ approaches $L$ as $n$ approaches infinity.
Now consider again the density function $\phi(w)=\mathbbm{1}_{\Q}(w)$.
Since the rational numbers are dense in the reals, no matter how granular we make a partition, we can always find either a rational or irrational value for $t_k$, and hence $\phi(t_k)$ can always be either 0 or 1. 
Consequently, the limit of the Riemann sum is dependant on the choice of $t_k$, and $\mathbbm{1}_{\Q}(w)$ is therefore not Riemann integrable, meaning the expression $\int_{0}^{1}\mathbbm{1}_{\Q}(w)dw$ is not computable.
This implies that heavier machinery is necessary to compute the required probability, and for this we build a measure-theoretic foundation.

\section{Measure Theoretic Definitions}
\begin{defn}[$\sigma$-Algebra]
    \label{defn:SA}
    Let $\mathcal{F}$ be a collection of subsets of $\Omega$, for some set $\Omega$.
    $\mathcal{F}$ is called a $\sigma$-Algebra if and only if:
    \begin{enumerate}
        \item $\Omega \in \mathcal{F}$, 
        \item for any $A \subseteq \Omega$, $A \in \mathcal{F} \implies 
            A^{c} \in \mathcal{F}$, 
        \item if $\{A_{i}\}_{i \in I}$ is a countable sequence of sets, where $A_i 
            \in \mathcal{F}$, for all $i \in I$, then $\bigcup_{i \in I}A_{i} \in 
            \mathcal{F}$.  
    \end{enumerate} 
\end{defn} 

Note that the intersection of an arbitrary family of $\sigma$-Algebras over the 
same set $\Omega$ is also a $\sigma$-Algebra over $\Omega$ (verify as an exercise). 

\begin{defn}[Generated $\sigma$-Algebra]
    \label{defn:gen-SA}
    Let $X$ be an arbitrary collection of subsets of $\Omega$. If $X$ is not a 
    $\sigma$-Algebra, we can recursively construct a $\sigma$-Algebra, denoted $[X]$,
    by adding subsets of $\Omega$ until all of requirements of the above definition
    are satisfied. $[X]$ is the smallest $\sigma$-Algebra of $\Omega$ that contains
    all elements of $X$. 
\end{defn}

The following example will clarify Definition~\ref{defn:gen-SA}.
Let $\Omega = \{1,2,3\}$ and $X=\{\{1\},\{1,2\},\{2,3\}\}$
Now to satisfy Definition~\ref{defn:gen-SA}-1, we add $\Omega$ to $X$ and obtain $[X]\subseteq\{\{1\},\{1,2\},\{2,3\},\{1,2,3\}\}$.
To satisfy Definition~\ref{defn:gen-SA}-2, we add the missing complements to obtain $[X]\subseteq\{\emptyset, \{1\},\{3\},\{1,2\},\{2,3\},\{1,2,3\}\}$.
To satisfy Definition~\ref{defn:gen-SA}-3, we see that the union of the sequence $\{1\},\{3\},\emptyset,\emptyset,\ldots$ also belongs to $[X]$, as does the complement of this union. Hence we have $[X]= \{\emptyset, \{1\},\{2\},\{3\},\{1,2\},\{2,3\},\{1,3\},\{1,2,3\}\}=\mathbb{P}(\Omega)$.
Note that the $\sigma$-algebra generated by a set $X$ need not be the power set of $\Omega$.
For example, consider $\Omega=\{1,2,3\}$ and $X=\{\emptyset,\{1\},\{2,3\},\{1,2,3\}\}$.
The reader may verify that $X=[X]$ in this case.

An important generated $\sigma$-Algebra is the Borel $\sigma$-algebra, denoted 
$\mathcal{B}(\R)$, and is defined over the extended real line, $\R^{*} = [-\infty,
+\infty]$. It is generated by the set of all open sets in $\R^{*}$, i.e., 
$\mathcal{B}(\R) = [\R^{*}]=[\{(a,b):a<b\}]$. For the rest of the notes, unless 
specified otherwise, we assume that $\R^{*}$ is equipped with the Borel $\sigma-$Algebra. 

One can verify that $\Q\in \mathcal{B}(\R)$ by observing the following: Choose $x\in \R$. 
Then $(-\infty,x)\cup(x,\infty)\in \mathcal{B}(\R)$ by Definition~\ref{defn:gen-SA}-3.
Then by Definition~\ref{defn:gen-SA}-2, $\{x\}\in \mathcal{B}(\R)$.
Again by Definition\ref{defn:gen-SA}-3, the union of any countable sequence of elements of $\mathcal{B}(\R)$ is in $\mathcal{B}(\R)$, and since $\Q$ is countable and $x$ was chosen arbitrarily, $\Q\in \mathcal{B}(\R)$.
This argument actually applies to any countable set as well.

\begin{defn}[Measurable Space]
    \label{defn:space}
    Given a set $\Omega$ and a $\sigma$-Algebra $\mathcal{F}$ over it, the ordered 
    pair $(\Omega,\mathcal{F})$ is called a measurable space. 
\end{defn}

\begin{defn}[Measurable Map]
    \label{defn:map}
    Let $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ be two measurable spaces. Let 
    $f \colon X \to Y$ be a map. $f$ is said to be measurable if and only if 
    for every $B \in \mathcal{B}$, 
    \[f^{-1}(B) = \{x \in X \colon f(x) \in B\} \in \mathcal{A}.\]
    If $f$ satisfies the requirements of a function, then $f$ is commonly referred 
    to as a measurable function. 
\end{defn}
A common abuse of notation depicts maps between two measurable (or measure) spaces 
$(X,\mathcal{A})$ and $(Y, \mathcal{B})$ as 
\[f \colon (X,\mathcal{A}) \to (Y,\mathcal{B}). \]
We call this an abuse of notation as $f$ still only maps elements of $X$ to elements
of $Y$ and does not make use of the $\sigma-$Algebras, $\mathcal{A}$ and $\mathcal{B}$. 

Note that there are two components that contribute to a map between measurable spaces
being measurable: (i) the choice of $\sigma$-Algebras $\mathcal{A}$ and $\mathcal{B}$,
and (ii) the map $f$ itself. 

Example:\\ Let $X=Y=\{1,2,3\}$, \\$\mathcal{A}=\{\{1,2,3\},\{1,2\},\{3\},\{2\},\{1,3\},\{2,3\},\{1\},\emptyset\}$ \\ $\mathcal{B}=\{\{1,2,3\},\{2,3\},\{1\},\emptyset\}$ \\

Define $f(1)=3,f(2)=2,f(3)=1$\\
Consider each $E\in \mathcal{B}$ \\
$E_1=\{1,2,3\},f(1)=3\in E_1,f(2)=2\in E_1,f(3)=1\in E_1$\\ $\implies f^{-1}(E_1)=\{1,2,3\}\in \mathcal{A}$ \checkmark\\

$E_2=\{2,3\},f(1)=3\in E_2,f(2)=2\in E_2,f(3)=1\notin E_2$\\ $\implies f^{-1}(E_2)=\{1,2\}\in \mathcal{A}$ \checkmark\\

$E_3=\{1\},f(1)=3\notin E_3,f(2)=2\notin E_3, f(3)=1\in E_3$\\ $\implies f^{-1}(E_3)=\{3\}\in \mathcal{A}$ \checkmark\\

$E_4=\emptyset$\\ $\implies f^{-1}(E_4)=\emptyset\in \mathcal{A}$ \checkmark\\

$\implies f$ is a measurable map. 

\begin{defn}[Map-Induced $\sigma$-Algebra]
    \label{defn:map-ind-SA}
    Let $(X,\mathcal{A})$ be a measurable space and let f be the map $f \colon X 
    \to Y$. We then define the map-induced $\sigma$-Algebra to be the set 
    \[\mathcal{B}_f = \{B \in \mathbb{P}(Y) \colon f^{-1}(B) \in \mathcal{A}\}. \]
    It is trivial to verify that $\mathcal{B}_f$ is indeed a $\sigma$-Algebra of $Y$. 
\end{defn}

Note that $\mathcal{B}_f$ is the largest $\sigma$-Algebra over $Y$ for which the 
given map $f \colon X \to Y$ is measurable. This is because $\mathcal{B}_f$ is 
constructed by considering all possible subsets of $Y$ via the power set of $Y$, 
denoted in Definition~\ref{defn:map-ind-SA} as $\mathbb{P}(Y)$. 

\begin{lem}
    A map $f$ from a measurable space $(X,\mathcal{A})$ to $\R^{*}$ is said to be 
    measurable if and only if for all $c \in \R$, 
    \[\{x \in X \colon f(x) > c\} \in \mathcal{A}. \]
\end{lem}

\begin{proof}
    $(\rightarrow)$ Note that every set of the form $(c,\infty)$, for $c \in \R$, 
    is an element of the Borel $\sigma-$Algebra, $\mathcal{B}(\R)$. Combining this 
    observation with the hypothesis that $f$ is a measurable map, we conclude the 
    proof in this direction. 

    $(\leftarrow)$ By hypothesis, we know that for all $c \in \R$, $f^{-1}((c,\infty))
    \in \mathcal{A}$. It suffices to show that for every open interval $(a,b) \subset
    \R$, we have that $f^{-1}((a,b)) \in \mathcal{A}$ as $\mathcal{B}(\R)$ is the 
    generated $\sigma-$Algebra of the set of open intervals in $\R$. 

    Since the preimage of a map is closed under the complement operation (verify as 
    exercise with elementary set theory, if necessary), i.e., $f^{-1}(X^{c}) = 
    (f^{-1}(X))^{c}$, we have that $f^{-1}((-\infty,c]) \in \mathcal{A}$, for all 
    $c \in \R$. For an arbitrary
    real $c \in \R$, we construct a sequence of sets $((-\infty,c-\frac{1}{n}])_{n 
    \in \N}$. Note that $\bigcup_{n \in \N}(-\infty,c-\frac{1}{n}] = (-\infty,c)$. 
    Since the preimage of the union (intersection) of sets is equivalent to the union
    (intersection) of preimages of the same sets (again, verify as an exercise using 
    elementary set theory, if necessary), we have that $f^{-1}(\bigcup_{n \in \N}(-\infty,
    c-\frac{1}{n}]) = \bigcup_{n \in \N}f^{-1}((-\infty,c-\frac{1}{n}])$. As each of the
    sets within the union on the right of the equality are elements of $\mathcal{A}$, we
    have that their union must also be contained within $\mathcal{A}$. Therefore, we
    have that $f^{-1}((-\infty,c)) \in \mathcal{A}$. Finally, since both $f^{-1}((c,
    \infty))$ and $f^{-1}((-\infty, c))$ are elements of $\mathcal{A}$, for all $c \in \R$, 
    we have that 
    \[f^{-1}((a,b)) = f^{-1}((-\infty,b) \cap (a,\infty)) = f^{-1}(-\infty, b) \cap f^{-1}
    (a, \infty) \in \mathcal{A}, \]
    concluding the non-trivial direction of the proof. 
    
\end{proof}

\begin{defn}[Measure]
    \label{defn:measure}
    Given a measurable space $(\Omega,\mathcal{F})$, a set $A\in \mathcal{F}$ is said to be a measurable set.
    A (positive) measure $\mu:\mathcal{F}\to [0,\infty]$ is a function such that
    $$\mu(\bigcup_{n=1}^{\infty}A_n)=\sum_{n=1}^{\infty}\mu(A_n)$$ if $A_i\cap A_j=\emptyset,
    \forall i\ne j$. 
\end{defn}
In other words, for any sequence of non-overlapping intervals, the measure of the union is equal to the sum of the measures of its elements (sometimes called \emph{sigma-additivity}).
Also of note is that $\infty$ is included in the codomain, as for example, there is a measure
called the Lebesgue measure (see Section~\ref{sec:lebesgue}) that measures the length of
intervals. Recall that $\Q\in\mathcal{B}(\R)$, and so $\mu(\Q)=\infty$ since there are an
infinite number of rationals.
\dhanush{Need to correct measure of $\Q$. }

\begin{defn}[Measure Space]
    \label{defn:measure-space}
    A measurable space $(\Omega,\mathcal{F})$ equipped with a measure $\mu$ is often 
    collectively denoted as the three-tuple $(\Omega,\mathcal{F},\mu)$ and is called 
    a measure space. 
\end{defn}

\subsection{Measure Theoretic Probability Theory}

Here we reinterpret the concepts described in the previous section through the lens of probability theory.
We think of the set $\Omega$ as the set of all possible outcomes in a probability experiment. For example, if the experiment is to roll a 6-sided die then $\Omega$ is the set of all possible trajectories (i.e. outcomes) that the toss of the die can take.
An event corresponds to a measurable set, i.e. any possible subset of the set of outcomes.
Thus $\mathcal{F}$ is the set of all events, and is given by subsets of trajectories.

In probability theory, a measurable map is referred to as a random variable.
We think of random variables as functions in the sense that they map outcomes to values.
For example, consider an experiment where we flip a coin. 
Either the coin lands heads (denoted by value 1), or tails (denoted by value zero). 
Let $X:\Omega\to\{0,1\}$ be the corresponding random variable.
The domain of $X$ consists of all possible trajectories the coin can fly through the air. One can imagine how difficult this set would be to define, as it includes all possible ways the coin can tumble or spin before it lands.
However, each trajectory corresponds to the coin either landing on heads or tails.
In this case the measurable space being mapped to is the labels $\Omega'=\{0,1\}$ coupled with the $\sigma$-algebra $\mathcal{F}'=\{\emptyset,\{0\},\{1\},\{0,1\}\}$.
The first element of $\mathcal{F}'$ is $\emptyset$ and represents both the empty set itself and the intersection of $\{0\}$ and $\{1\}$.
This corresponds to the events that the coin lands on both heads and tails, and the coin lands on neither heads nor tails.
The second element represents the event that the coin lands on tails, the third element represents the event that the coin lands on heads, and the final element of $\mathcal{F}'$ represents the event that the coin lands on either heads or tails.

We interpret a positive measure as a probability, which is a function that maps sets in $\mathcal{F}'$ to $[0,1]$.
Instead of $\mu$, we denote this measure as $\Pr[\cdot]$.
In the coin toss example we define, $\Pr[\emptyset]=0$, $\Pr[\{0\}]=\Pr[\{1\}]=1/2$ and $\Pr[\{0,1\}]=1$.
The first probability is 0 since it is not possible for the coin to land on both heads and tails or neither, and the last probability is 1 since the coin is guaranteed to land on either heads or tails.
Notice how this satisfies the probability of a measure, since for any countable non-overlapping sequence of subsets of $\mathcal{F}'$, the measure of the union of the sequence is equal to the sum of the measures of elements of the sequence. In this case
$$\Pr[\{0\}\cup\{1\}\cup\emptyset]=\Pr[\{0,1\}]=1=1/2+1/2+0=\Pr[\{0\}]+\Pr[\{1\}]+\Pr[\emptyset]$$
is one such example of a non-overlapping sequence, as the intersection of these sets is empty.
Lastly, a measurable space equipped with a probability measure $(\Omega,\mathcal{F},\Pr)$ is referred to as a \emph{probability space}.

\section{Lebesgue Measure and Integral}
\label{sec:lebesgue}
\begin{defn}[Lebesgue Measure (in one-dimension)]
    Given an interval $(a,b) \subseteq \R$, the Lebesgue measure, denoted $\mu_L((a,b))$, 
    is defined to be the length of the interval, i.e., $\mu_L((a,b)) = b-a$. 
\end{defn}
Note that the above definition is naturally extended to higher dimensions. When the 
Lebesgue measure is equipped to $n-$dimensional Euclidean space, the measure of a subset 
$S \subseteq \R^{n}$ is corresponds to the $n-$dimensional variant of length applied to 
the subset $S$. For example, when $n=2$, the Lebesgue measure corresponds to the area of 
$S \subset \R^2$, whereas if $n=3$, the Lebesgue measure corresponds to the volume of $S
\subset \R^3$. 

Further, while the definition of the Lebesgue measure invovles open subsets of Euclidean 
space, it is easy to extend this definition to closed subsets with the help of partitions
(see Definition~\ref{defn:partition}). \dhanush{I'll come back and add more details if 
necessary. } 

\subsection{Construction of the Lebesgue Integral}
Consider a measurable function $f \colon (\Omega, \mathcal{F}, \mu) \to (\R,\mathcal{B}(\R))$. 
We consider varying forms of $X$ (in increasing complexity) and define the Lebesgue integral 
of $X$ with respect to the measure $\mu$. 

\emph{1. Indicator Functions:  X = $\mathbbm{1}_A$, for some $A \in \mathcal{F}$. }

\[\int{X d\mu} = \mu(A). \]

\emph{2. Simple Functions: $X = \sum_{i=1}^{n}\alpha_{i}\ind_{A_{i}}$, where $A_{i} \in \mathcal{F}$
and $\alpha_{i} \in \R$, for all $i \in \{1,2,\dots,n\}$.} 

\begin{align*}
    \int{X d\mu} = & \sum_{i=1}^{n}\alpha_{i} \int{\ind_{A_{i}} d\mu} \\
                 = & \sum_{i=1}^{n}\alpha_{i} \mu(A_{i}). 
\end{align*}

\emph{3. Positive Measurable Functions: $X \geq 0$. }

\dhanush{Need to add figures at this point. }

\clearpage

\end{document}
